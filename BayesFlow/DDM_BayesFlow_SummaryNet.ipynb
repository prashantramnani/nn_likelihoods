{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "# print(tqdm.__version__)\n",
    "\n",
    "from models import DeepConditionalModel, InvariantNetwork\n",
    "from losses import maximum_likelihood_loss\n",
    "from inn_utils import train_online_ml\n",
    "# from viz import plot_losses, plot_metrics_params\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import psutil\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import scipy as scp\n",
    "from scipy.stats import gamma\n",
    "import time\n",
    "\n",
    "import cddm_data_simulation as cds\n",
    "import kde_training_utilities as kde_util\n",
    "import kde_class as kde\n",
    "import boundary_functions as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator function for 2-choice data using ddm_flexbound\n",
    "def data_generator_ddm_flexbound(batch_size):\n",
    "    v = np.random.uniform(-3, 3, batch_size)\n",
    "    a = np.random.uniform(0.3, 2.5, batch_size)\n",
    "    w = np.random.uniform(0.1, 0.9, batch_size)\n",
    "    \n",
    "    # Number of paths to be sampled for each batch    \n",
    "    n_samples = 10000 \n",
    "    \n",
    "    # Bool to determine how to put 'rt' and 'choice_made' together\n",
    "    multiply = True \n",
    "    \n",
    "    boundary_function = bf.constant\n",
    "        \n",
    "    X_train = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        out = cds.ddm_flexbound(v[i], \n",
    "                                a[i], \n",
    "                                w[i],\n",
    "                                ndt = 0.5,\n",
    "                                delta_t = 0.001, \n",
    "                                s = np.sqrt(2),\n",
    "                                max_t = 20,\n",
    "                                n_samples = n_samples,\n",
    "                                boundary_fun = boundary_function,\n",
    "                                boundary_multiplicative = True, \n",
    "                                boundary_params = {})\n",
    "                                #boundary_params = {\"theta\": 0.01})\n",
    "            \n",
    "        data = np.concatenate((out[0], out[1]), axis=1)\n",
    "            \n",
    "        X_train.append(data)    \n",
    "        \n",
    "    X_train = np.array(X_train)         \n",
    "    # Concatenating a, v and w\n",
    "    param = np.concatenate((a.reshape(-1, 1), v.reshape(-1, 1), w.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    return tf.convert_to_tensor(X_train, dtype=tf.float32), tf.convert_to_tensor(param, dtype=tf.float32)\n",
    "    \n",
    "\n",
    "# start = time.time()\n",
    "# a, b = data_generator_ddm_flexbound(1)    \n",
    "# end = time.time()\n",
    "# print(\"Data generation took: {} time\".format(end - start))\n",
    "# print(a[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_opt(n_inv_blocks, summary_dim, global_step):\n",
    "    \"\"\"Loads a GMM model given the number of invertible blocks.\"\"\"\n",
    "    \n",
    "    # Create model\n",
    "    summary_net = InvariantNetwork(summary_dim, n_equiv=3)\n",
    "    model = DeepConditionalModel(inv_meta, n_inv_blocks, theta_dim, summary_net=summary_net, permute=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    # Checkpoint model\n",
    "    checkpoint = tf.train.Checkpoint(step=global_step, optimizer=optimizer, net=model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint, './checkpoints/ddm_flexbound_summarynet_{}'.format(n_inv_blocks), max_to_keep=2)\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    \n",
    "    return model, optimizer, manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_inv_blocks, summary_dim):\n",
    "    \"\"\"\n",
    "    Runs the Gausian Distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    model, optimizer, manager = load_model_and_opt(n_inv_blocks, summary_dim, global_step)\n",
    "    \n",
    "    for ep in range(1, epochs+1):\n",
    "        with tqdm(total=iterations_per_epoch, desc='Training epoch {}'.format(ep)) as p_bar:\n",
    "\n",
    "            # Run training loop\n",
    "            train_online_ml(model, optimizer, data_generator_ddm_flexbound, iterations_per_epoch, \n",
    "                            batch_size, p_bar=p_bar, clip_value=clip_value, global_step=global_step, \n",
    "                            transform=None, n_smooth=100)\n",
    "            \n",
    "            manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the various configurations\n",
    "inv_meta = {\n",
    "    'n_units': [128, 128, 128],\n",
    "    'activation': 'elu',\n",
    "    'w_decay': 0.0,\n",
    "    'initializer': 'glorot_uniform'\n",
    "}\n",
    "\n",
    "n_inv = 10\n",
    "theta_dim = 3\n",
    "# params_names = [r'$\\mu_{}$'.format(i+1) for i in range(theta_dim)]\n",
    "global_step = tf.Variable(0, dtype=tf.int32)\n",
    "batch_size = 50\n",
    "summary_dim = 128\n",
    "epochs = 20\n",
    "iterations_per_epoch = 100\n",
    "n_samples_posterior = 2000\n",
    "starter_learning_rate = 0.001\n",
    "decay_steps = 1000\n",
    "decay_rate = .99\n",
    "clip_value = 5.\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, \n",
    "                                           decay_steps, decay_rate, staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b46786b0fd1469eb8a1d31408f9762e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training epoch 1', style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py:562: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "INPUT (50, 10000, 2)\n",
      "IN SUMMARY NET\n",
      "SUMMARY OUT (50, 128)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ff6c98d548bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-7568960ebf8a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(n_inv_blocks, summary_dim)\u001b[0m\n\u001b[1;32m     12\u001b[0m             train_online_ml(model, optimizer, data_generator_ddm_flexbound, iterations_per_epoch, \n\u001b[1;32m     13\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                             transform=None, n_smooth=100)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Intern/HDDM_nn/nn_likelihoods/BayesFlow/inn_utils.py\u001b[0m in \u001b[0;36mtrain_online_ml\u001b[0;34m(model, optimizer, data_generator, iterations, batch_size, p_bar, clip_value, global_step, transform, n_smooth)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# One step backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclip_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_PackGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_PackGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;34m\"\"\"Gradient for pack op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"N\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(value, num, axis, name)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot infer num from shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36munpack\u001b[0;34m(value, num, axis, name)\u001b[0m\n\u001b[1;32m  11978\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m  11979\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unpack\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11980\u001b[0;31m         name, _ctx.post_execution_callbacks, value, \"num\", num, \"axis\", axis)\n\u001b[0m\u001b[1;32m  11981\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11982\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(n_inv, summary_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hddm",
   "language": "python",
   "name": "hddm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
